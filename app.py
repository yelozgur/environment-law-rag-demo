import os
import streamlit as st
import fitz
import numpy as np
import json
import time
from pathlib import Path
from groq import Groq
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions
from sentence_transformers import SentenceTransformer

# Environment variables yÃ¼kle
load_dotenv()

# Streamlit sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="Ã‡evre Hukuku UzmanÄ±",
    page_icon="âš–ï¸",
    layout="wide"
)

# Cache'lenmiÅŸ fonksiyonlar
@st.cache_resource
def init_embedding_model():
    """Embedding modelini yÃ¼kle"""
    try:
        # Hafif, hÄ±zlÄ± bir model
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        return model
    except Exception as e:
        st.error(f"Embedding model yÃ¼klenemedi: {e}")
        return None

@st.cache_resource  
def init_chroma_client():
    """ChromaDB client'Ä±nÄ± baÅŸlat"""
    try:
        # Streamlit Cloud iÃ§in persist directory
        persist_dir = "./chroma_db"
        Path(persist_dir).mkdir(exist_ok=True)
        
        client = chromadb.PersistentClient(path=persist_dir)
        return client
    except Exception as e:
        st.error(f"ChromaDB baÅŸlatma hatasÄ±: {e}")
        return None

class ChromaRAGSystem:
    def __init__(self):
        """ChromaDB tabanlÄ± RAG sistemi baÅŸlat"""
        self.embedding_model = init_embedding_model()
        self.chroma_client = init_chroma_client()
        
        # Groq API
        self.groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        self.model_name = "llama3-8b-8192"
        
        # Dosya yollarÄ±
        self.pdf_path = "documents/cevre_yasasi.pdf"
        self.metadata_path = "vectorstore/metadata.json"
        
        # Koleksiyon adÄ±
        self.collection_name = "environment_law_docs"
        
        # KlasÃ¶rleri oluÅŸtur
        Path("documents").mkdir(exist_ok=True)
        Path("vectorstore").mkdir(exist_ok=True)
        
        # Session state'i baÅŸlat
        if 'vectorstore_loaded' not in st.session_state:
            st.session_state.vectorstore_loaded = False
        if 'chunks_count' not in st.session_state:
            st.session_state.chunks_count = 0
            
        # Vector store'u yÃ¼kle
        self._load_vectorstore()
    
    def _load_vectorstore(self):
        """ChromaDB vector store'u yÃ¼kle"""
        try:
            # KoleksiyonlarÄ± listele
            collections = self.chroma_client.list_collections()
            collection_names = [col.name for col in collections]
            
            if self.collection_name in collection_names:
                self.collection = self.chroma_client.get_collection(self.collection_name)
                count = self.collection.count()
                
                st.session_state.vectorstore_loaded = True
                st.session_state.chunks_count = count
                
                # Metadata yÃ¼kle
                if os.path.exists(self.metadata_path):
                    with open(self.metadata_path, 'r', encoding='utf-8') as f:
                        self.metadata = json.load(f)
                else:
                    self.metadata = {"source": self.pdf_path, "chunks_count": count}
                
                return True
            else:
                st.session_state.vectorstore_loaded = False
                return False
                
        except Exception as e:
            st.warning(f"Vector store yÃ¼klenemedi: {e}")
            st.session_state.vectorstore_loaded = False
            return False
    
    def extract_text_from_pdf(self, pdf_path=None):
        """PDF'den metin Ã§Ä±kar ve parÃ§alara ayÄ±r"""
        chunks = []
        metadata_list = []
        
        try:
            # PDF yolu
            if pdf_path is None:
                pdf_path = self.pdf_path
            
            if not os.path.exists(pdf_path):
                st.error(f"PDF dosyasÄ± bulunamadÄ±: {pdf_path}")
                return [], []
            
            # PDF'den metin Ã§Ä±kar
            doc = fitz.open(pdf_path)
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text().strip()
                
                if text:
                    # SayfayÄ± paragraflara bÃ¶l
                    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
                    
                    for para_num, paragraph in enumerate(paragraphs):
                        if 100 < len(paragraph) < 2000:  # Boyut kontrolÃ¼
                            chunks.append(paragraph)
                            metadata_list.append({
                                "page": page_num + 1,
                                "paragraph": para_num + 1,
                                "source": os.path.basename(pdf_path)
                            })
            
            doc.close()
            
            if chunks:
                st.success(f"âœ… {len(chunks)} metin parÃ§asÄ± Ã§Ä±karÄ±ldÄ±")
            else:
                st.warning("PDF'den metin Ã§Ä±karÄ±lamadÄ±!")
            
            return chunks, metadata_list
            
        except Exception as e:
            st.error(f"PDF iÅŸleme hatasÄ±: {e}")
            return [], []
    
    def create_embeddings(self, texts):
        """Metinler iÃ§in embedding oluÅŸtur"""
        if self.embedding_model is None:
            st.error("Embedding model yÃ¼klenemedi!")
            return None
        
        try:
            embeddings = self.embedding_model.encode(
                texts,
                show_progress_bar=False,
                convert_to_numpy=True,
                normalize_embeddings=True
            )
            return embeddings
        except Exception as e:
            st.error(f"Embedding oluÅŸturma hatasÄ±: {e}")
            return None
    
    def create_vectorstore(self):
        """PDF'den vector store oluÅŸtur"""
        if not os.path.exists(self.pdf_path):
            st.error(f"PDF dosyasÄ± bulunamadÄ±: {self.pdf_path}")
            return False
        
        # Metin Ã§Ä±kar
        with st.spinner("ğŸ“„ PDF iÅŸleniyor..."):
            chunks, metadata_list = self.extract_text_from_pdf()
        
        if not chunks:
            st.error("PDF'den metin Ã§Ä±karÄ±lamadÄ±!")
            return False
        
        # Embedding oluÅŸtur
        with st.spinner("ğŸ”¨ Embedding'ler oluÅŸturuluyor..."):
            embeddings = self.create_embeddings(chunks)
            
            if embeddings is None:
                return False
        
        # ChromaDB'ye ekle
        with st.spinner("ğŸ—ï¸ Vector store oluÅŸturuluyor..."):
            try:
                # Eski koleksiyonu sil (varsa)
                try:
                    self.chroma_client.delete_collection(self.collection_name)
                except:
                    pass
                
                # Yeni koleksiyon oluÅŸtur
                self.collection = self.chroma_client.create_collection(
                    name=self.collection_name,
                    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(
                        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                    )
                )
                
                # Batch ekleme
                batch_size = 50
                for i in range(0, len(chunks), batch_size):
                    end_idx = min(i + batch_size, len(chunks))
                    
                    batch_chunks = chunks[i:end_idx]
                    batch_embeddings = embeddings[i:end_idx]
                    batch_metadata = metadata_list[i:end_idx]
                    
                    # ID'ler oluÅŸtur
                    ids = [f"chunk_{j}" for j in range(i, end_idx)]
                    
                    # Koleksiyona ekle
                    self.collection.add(
                        embeddings=batch_embeddings.tolist(),
                        documents=batch_chunks,
                        metadatas=batch_metadata,
                        ids=ids
                    )
                
                # Metadata kaydet
                metadata = {
                    "source": self.pdf_path,
                    "chunks_count": len(chunks),
                    "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2"
                }
                
                with open(self.metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                
                # Session state'i gÃ¼ncelle
                st.session_state.vectorstore_loaded = True
                st.session_state.chunks_count = len(chunks)
                self.metadata = metadata
                
                st.success(f"âœ… Vector store oluÅŸturuldu: {len(chunks)} parÃ§a")
                return True
                
            except Exception as e:
                st.error(f"Vector store oluÅŸturma hatasÄ±: {e}")
                return False
    
    def search(self, query, k=5):
        """Vector store'da benzer parÃ§alarÄ± ara"""
        if not st.session_state.get('vectorstore_loaded', False):
            return []
        
        try:
            # ChromaDB'de ara
            results = self.collection.query(
                query_texts=[query],
                n_results=k,
                include=["documents", "metadatas", "distances"]
            )
            
            # SonuÃ§larÄ± formatla
            formatted_results = []
            if results['documents']:
                for i, doc in enumerate(results['documents'][0]):
                    distance = results['distances'][0][i]
                    similarity = 1 - distance  # Cosine benzerliÄŸi
                    
                    formatted_results.append({
                        'text': doc,
                        'distance': float(distance),
                        'similarity': float(similarity),
                        'page': results['metadatas'][0][i].get('page', 0),
                        'source': results['metadatas'][0][i].get('source', 'Unknown')
                    })
            
            return formatted_results
            
        except Exception as e:
            st.error(f"Arama hatasÄ±: {e}")
            return []
    
    def ask_question(self, query, k=5):
        """Soru sor ve yanÄ±t al"""
        if not st.session_state.get('vectorstore_loaded', False):
            return {
                "answer": "LÃ¼tfen Ã¶nce PDF yÃ¼kleyin ve vector store oluÅŸturun.",
                "sources": [],
                "confidence": 0.0
            }
        
        # Benzer parÃ§alarÄ± ara
        with st.spinner("ğŸ” Ä°lgili dokÃ¼manlar aranÄ±yor..."):
            results = self.search(query, k)
        
        if not results:
            return {
                "answer": "ÃœzgÃ¼nÃ¼m, ilgili dokÃ¼man bulunamadÄ±.",
                "sources": [],
                "confidence": 0.0
            }
        
        # Context oluÅŸtur
        context_parts = []
        for i, result in enumerate(results):
            page_info = f" [Sayfa {result['page']}]" if result.get('page') else ""
            context_parts.append(f"[ParÃ§a {i+1}{page_info}] {result['text']}")
        
        context = "\n\n---\n\n".join(context_parts)
        
        # Ortalama benzerlik
        avg_similarity = np.mean([r['similarity'] for r in results])
        
        # Prompt oluÅŸtur
        prompt = f"""Sen bir Ã§evre hukuku uzmanÄ± avukatsÄ±n.

KullanÄ±cÄ± Sorusu: {query}

Ä°lgili Mevzuat ParÃ§alarÄ±:
{context}

Ã–nemli Kurallar:
1. SADECE yukarÄ±daki mevzuat parÃ§alarÄ±na dayan
2. Belgede olmayan bilgi EKLEME
3. AnlaÅŸÄ±lÄ±r, profesyonel hukuki TÃ¼rkÃ§e kullan
4. Sayfa numaralarÄ±na referans ver
5. EÄŸer konu net deÄŸilse, "Belgede bu konu net belirtilmemiÅŸtir" de

YanÄ±t:"""
        
        # Groq API ile yanÄ±t al
        try:
            response = self.groq_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system", 
                        "content": "Sen bir Ã§evre hukuku uzmanÄ± avukatsÄ±n. Sadece verilen kaynaklara dayanarak cevap ver."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            answer = response.choices[0].message.content
            
            return {
                "answer": answer,
                "sources": results,
                "confidence": avg_similarity,
                "query": query
            }
            
        except Exception as e:
            st.error(f"API hatasÄ±: {e}")
            return {
                "answer": f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}",
                "sources": [],
                "confidence": 0.0
            }
    
    def clear_vectorstore(self):
        """Vector store'u temizle"""
        try:
            # Koleksiyonu sil
            self.chroma_client.delete_collection(self.collection_name)
            
            # Metadata dosyasÄ±nÄ± sil
            if os.path.exists(self.metadata_path):
                os.remove(self.metadata_path)
            
            # ChromaDB dizinini temizle
            import shutil
            if os.path.exists("./chroma_db"):
                shutil.rmtree("./chroma_db")
                os.makedirs("./chroma_db")
            
            # Session state'i sÄ±fÄ±rla
            st.session_state.vectorstore_loaded = False
            st.session_state.chunks_count = 0
            
            # Client'Ä± yeniden baÅŸlat
            self.chroma_client = init_chroma_client()
            
            return True
            
        except Exception as e:
            st.error(f"Temizleme hatasÄ±: {e}")
            return False

def main():
    """Ana Streamlit uygulamasÄ±"""
    st.title("âš–ï¸ Ã‡evre Hukuku Uzman AsistanÄ±")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ“‚ DokÃ¼man YÃ¶netimi")
        
        # PDF dosya durumu
        pdf_path = "documents/cevre_yasasi.pdf"
        pdf_exists = os.path.exists(pdf_path)
        
        if pdf_exists:
            file_size = os.path.getsize(pdf_path) / 1024 / 1024
            st.success(f"âœ… PDF mevcut: {file_size:.2f} MB")
            
            if st.button("ğŸ”„ Vector Store OluÅŸtur", type="primary", use_container_width=True):
                if 'rag_system' not in st.session_state:
                    st.session_state.rag_system = ChromaRAGSystem()
                
                rag = st.session_state.rag_system
                success = rag.create_vectorstore()
                if success:
                    st.success("âœ… Vector store baÅŸarÄ±yla oluÅŸturuldu!")
                    time.sleep(2)
                    st.rerun()
        else:
            st.error("âŒ PDF bulunamadÄ±!")
            st.info("LÃ¼tfen `documents/cevre_yasasi.pdf` dosyasÄ±nÄ± yÃ¼kleyin.")
        
        st.markdown("---")
        st.header("âš™ï¸ Ayarlar")
        
        k_results = st.slider(
            "Aranacak benzer dokÃ¼man sayÄ±sÄ±",
            min_value=1,
            max_value=10,
            value=5
        )
        
        st.markdown("---")
        st.subheader("ğŸ—„ï¸ Vector Store Durumu")
        
        # Vector store durumu
        if st.session_state.get('vectorstore_loaded', False):
            st.success("âœ… Vector store yÃ¼klÃ¼")
            chunks_count = st.session_state.get('chunks_count', 0)
            st.info(f"ğŸ“Š {chunks_count} parÃ§a")
            
            # Metadata gÃ¶ster
            if os.path.exists("vectorstore/metadata.json"):
                try:
                    with open("vectorstore/metadata.json", 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    st.caption(f"OluÅŸturulma: {metadata.get('created_at', 'Unknown')}")
                except:
                    pass
        else:
            st.warning("âš ï¸ Vector store yÃ¼klenmedi")
        
        # Temizleme butonu
        st.markdown("---")
        if st.button("ğŸ—‘ï¸ Vector Store'u Temizle", type="secondary", use_container_width=True):
            if 'rag_system' in st.session_state:
                rag = st.session_state.rag_system
                success = rag.clear_vectorstore()
                if success:
                    st.success("âœ… Vector store temizlendi!")
                    time.sleep(2)
                    st.rerun()
            else:
                st.warning("RAG sistemi baÅŸlatÄ±lmamÄ±ÅŸ")
        
        # Yenile butonu
        st.markdown("---")
        if st.button("ğŸ”„ SayfayÄ± Yenile", type="secondary", use_container_width=True):
            st.rerun()
    
    # Ana iÃ§erik
    # RAG sistemini baÅŸlat
    if 'rag_system' not in st.session_state:
        st.session_state.rag_system = ChromaRAGSystem()
    
    rag = st.session_state.rag_system
    
    # Vector store durumu
    vectorstore_loaded = st.session_state.get('vectorstore_loaded', False)
    
    if vectorstore_loaded:
        # BaÅŸarÄ±lÄ± yÃ¼kleme
        chunks_count = st.session_state.get('chunks_count', 0)
        
        st.success(f"âœ… Sistem hazÄ±r! {chunks_count} metin parÃ§asÄ± yÃ¼klendi.")
        
        # Soru sorma bÃ¶lÃ¼mÃ¼
        st.subheader("â“ Soru Sor")
        
        query = st.text_area(
            "Ã‡evre hukuku ile ilgili sorunuzu yazÄ±n:",
            placeholder="Ã–rnek: Ã‡evre kirliliÄŸi iÃ§in cezai yaptÄ±rÄ±mlar nelerdir? AtÄ±k yÃ¶netimi yÃ¼kÃ¼mlÃ¼lÃ¼kleri nelerdir? Ã‡evre izinleri nasÄ±l alÄ±nÄ±r?",
            height=100
        )
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button("ğŸ” YanÄ±t Al", type="primary", use_container_width=True) and query:
                # YanÄ±tÄ± al
                result = rag.ask_question(query, k=k_results)
                
                # YanÄ±tÄ± gÃ¶ster
                st.markdown("---")
                st.subheader("ğŸ¤– Uzman YanÄ±tÄ±")
                
                with st.container():
                    st.markdown(result["answer"])
                    
                    # Ä°statistikler
                    cols = st.columns(3)
                    with cols[0]:
                        st.metric("GÃ¼ven Skoru", f"{result['confidence']:.2%}")
                    with cols[1]:
                        st.metric("KullanÄ±lan Kaynak", len(result["sources"]))
                    with cols[2]:
                        if result["sources"]:
                            first_page = result["sources"][0].get('page', 0)
                            if first_page > 0:
                                st.metric("Ä°lk Sayfa", f"{first_page}")
                
                # KaynaklarÄ± gÃ¶ster
                if result["sources"]:
                    with st.expander(f"ğŸ“š KullanÄ±lan Kaynaklar ({len(result['sources'])})", expanded=False):
                        for i, source in enumerate(result["sources"], 1):
                            st.markdown(f"**Kaynak {i}**")
                            
                            col_a, col_b = st.columns([1, 4])
                            with col_a:
                                st.metric("Benzerlik", f"{source['similarity']:.2%}")
                                if source.get('page'):
                                    st.caption(f"Sayfa: {source['page']}")
                            
                            with col_b:
                                st.info(f"{source['text'][:500]}...")
                            
                            st.markdown("---")
        
        with col2:
            if st.button("ğŸ“Š Durum", type="secondary", use_container_width=True):
                st.rerun()
    
    else:
        # Vector store yÃ¼klenemedi
        st.warning("""
        ### âš ï¸ Vector Store YÃ¼klenmedi
        
        **AdÄ±mlar:**
        1. **PDF kontrolÃ¼** â†’ Sidebar'da PDF'nin mevcut olduÄŸunu gÃ¶rÃ¼n
        2. **Vector store oluÅŸtur** â†’ "Vector Store OluÅŸtur" butonuna tÄ±klayÄ±n
        3. **Bekleyin** â†’ PDF iÅŸlenecek ve embedding'ler oluÅŸturulacak
        
        **ğŸ“ Mevcut Dosyalar:**
        ```
        /mount/src/environment-law-rag-demo/
        â”œâ”€â”€ documents/
        â”‚   â””â”€â”€ cevre_yasasi.pdf    âœ… VAR
        â”œâ”€â”€ vectorstore/
        â”‚   â”œâ”€â”€ index.faiss         âš ï¸ FAISS (kullanÄ±lmayacak)
        â”‚   â””â”€â”€ chunks.npy          âš ï¸ FAISS (kullanÄ±lmayacak)
        â”œâ”€â”€ chroma_db/              âœ… ChromaDB iÃ§in
        â”œâ”€â”€ app.py
        â””â”€â”€ requirements.txt
        ```
        
        **â„¹ï¸ Not:** Mevcut FAISS dosyalarÄ± kullanÄ±lmayacak, yeni ChromaDB vector store oluÅŸturulacak.
        """)
        
        # HÄ±zlÄ± bilgiler
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("PDF Durumu", "âœ… Mevcut" if pdf_exists else "âŒ Eksik")
        
        with col2:
            st.metric("ChromaDB", "âœ… HazÄ±r")
        
        with col3:
            st.metric("Groq API", "âœ… HazÄ±r")
    
    # Footer
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.caption("âš¡ Powered by Groq API")
    with col2:
        st.caption("ğŸ” ChromaDB Vector Search")
    with col3:
        st.caption("âš–ï¸ Ã‡evre Hukuku UzmanÄ±")

if __name__ == "__main__":
    # API key kontrolÃ¼
    groq_key = os.getenv("GROQ_API_KEY")
    
    if not groq_key:
        st.error("""
        ### âš ï¸ GROQ_API_KEY ayarlanmamÄ±ÅŸ!
        
        **Ã‡Ã¶zÃ¼m:**
        1. **Streamlit Cloud Secrets**'Ä± kontrol edin
        2. **.env dosyasÄ±** oluÅŸturun
        3. **Manuel olarak** API key girin
        
        **Secrets formatÄ± (.streamlit/secrets.toml):**
        ```toml
        GROQ_API_KEY = "sk-..."
        ```
        """)
        
        # Debug iÃ§in API key giriÅŸi
        with st.expander("ğŸ”‘ API Key GiriÅŸi (Debug)"):
            groq_input = st.text_input("GROQ_API_KEY:", type="password")
            if groq_input:
                os.environ["GROQ_API_KEY"] = groq_input
                st.success("API Key kaydedildi! SayfayÄ± yenileyin.")
                if st.button("ğŸ”„ Yenile"):
                    st.rerun()
    else:
        main()
